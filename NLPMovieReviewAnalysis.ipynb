{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import string\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve\n",
    "\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/IMDB_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = df.loc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip html text\n",
    "soup = BeautifulSoup(review, \"lxml\")\n",
    "data = soup.get_text()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lower case all text\n",
    "data = data.lower()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "punctuation = string.punctuation.replace('.', '')\n",
    "data = data.translate(str.maketrans('', '', punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'\\s+')\n",
    "data = re.sub(pattern, ' ', data.replace('.', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "data = word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of nltk's stopwords\n",
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "data = [word for word in data if word not in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a PortStemmer object\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tokens into their stem\n",
    "data = [stemmer.stem(token) for token in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessor(review):\n",
    "    # Strip html text\n",
    "    soup = BeautifulSoup(review, \"lxml\")\n",
    "    data = soup.get_text()\n",
    "    # Lower case all text\n",
    "    data = data.lower()\n",
    "    # Remove edge cases with multiple periods\n",
    "    pattern = re.compile(r'\\s+')\n",
    "    data = re.sub(pattern, ' ', data.replace('.', ' '))\n",
    "    # Remove punctuation and other special characters\n",
    "    pattern = r'[^a-zA-Z\\s]'\n",
    "    data = re.sub(pattern, '', data)\n",
    "    # Tokenize\n",
    "    data = word_tokenize(data)\n",
    "    # Get list of nltk's stopwords\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    # Remove stop words\n",
    "    data = [word for word in data if word not in stopwords_list]\n",
    "    # Initialize a PortStemmer object\n",
    "    stemmer = PorterStemmer()\n",
    "    # Convert the tokens into their stem\n",
    "    data = [stemmer.stem(token) for token in data]\n",
    "    # Convert the list of words back into\n",
    "    # a string by joining each word with a space\n",
    "    data = ' '.join(data)\n",
    "    # Remove double spaces\n",
    "    data = data.replace('  ', ' ')\n",
    "    # Remove opening and trailing spaces\n",
    "    data = data.strip()\n",
    "    # Return the cleaned text data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(text_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.review[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of words per review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\n",
    "length_good_reviews = df[df['sentiment'] == 'positive']['review'].str.split().map(lambda x: len(x))\n",
    "ax1.hist(length_good_reviews, color='blue')\n",
    "ax1.set_title('Positive Reviews')\n",
    "length_bad_reviews = df[df['sentiment'] == 'negative']['review'].str.split().map(lambda x: len(x))\n",
    "ax2.hist(length_bad_reviews, color='green')\n",
    "ax2.set_title('Negative Reviews')\n",
    "fig.suptitle('Words in texts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean word length per review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 8))\n",
    "pos_word = df[df['sentiment'] == 'positive']['review'].str.split().apply(lambda x: [\n",
    "    len(i) for i in x])\n",
    "sns.distplot(pos_word.map(lambda x: np.mean(x)), ax=ax1, color='blue')\n",
    "ax1.set_title('Positive Reviews')\n",
    "neg_word = df[df['sentiment'] == 'negative']['review'].str.split().apply(lambda x: [\n",
    "    len(i) for i in x])\n",
    "sns.distplot(neg_word.map(lambda x: np.mean(x)), ax=ax2, color='green')\n",
    "ax2.set_title('Negative Reviews')\n",
    "fig.suptitle('Mean word length per review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words(text):\n",
    "    words = []\n",
    "    for x in text:\n",
    "        for y in x.split():\n",
    "            words.append(y.strip())\n",
    "    return words\n",
    "all_words = get_all_words(df.review)\n",
    "all_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(all_words)\n",
    "most_common = counter.most_common(10)\n",
    "most_common = dict(most_common)\n",
    "most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/madz2000/sentiment-analysis-cleaning-eda-bert-88-acc/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_text_ngrams(text, num_words, ngram):\n",
    "    vec = CountVectorizer(ngram_range=(ngram, ngram)).fit(text)\n",
    "    bag_of_words = vec.transform(text)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx])\n",
    "                  for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "    return words_freq[:num_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_uni = get_top_text_ngrams(df.review, 20, 1)\n",
    "most_common_uni = dict(most_common_uni)\n",
    "temp = pd.DataFrame(columns=[\"Common_words\", 'Count'])\n",
    "temp[\"Common_words\"] = list(most_common_uni.keys())\n",
    "temp[\"Count\"] = list(most_common_uni.values())\n",
    "fig = px.bar(temp, x=\"Count\", y=\"Common_words\", title='Common Words in All Reviews', orientation='h',\n",
    "             width=700, height=700, color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_uni_pos = get_top_text_ngrams(df.review[df.sentiment=='positive'], 20, 1)\n",
    "most_common_uni_pos = dict(most_common_uni_pos)\n",
    "temp = pd.DataFrame(columns=[\"Common_words\", 'Count'])\n",
    "temp[\"Common_words\"] = list(most_common_uni_pos.keys())\n",
    "temp[\"Count\"] = list(most_common_uni_pos.values())\n",
    "fig = px.bar(temp, x=\"Count\", y=\"Common_words\", title='Common Words in Positive Reviews', orientation='h',\n",
    "             width=700, height=700, color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_uni_neg = get_top_text_ngrams(df.review[df.sentiment=='negative'], 20, 1)\n",
    "most_common_uni_neg = dict(most_common_uni_neg)\n",
    "temp = pd.DataFrame(columns=[\"Common_words\", 'Count'])\n",
    "temp[\"Common_words\"] = list(most_common_uni_neg.keys())\n",
    "temp[\"Count\"] = list(most_common_uni_neg.values())\n",
    "fig = px.bar(temp, x=\"Count\", y=\"Common_words\", title='Commmon Words in Negative Reviews', orientation='h',\n",
    "             width=700, height=700, color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_bi = get_top_text_ngrams(df.review,20,2)\n",
    "most_common_bi = dict(most_common_bi)\n",
    "temp = pd.DataFrame(columns = [\"Common_words\" , 'Count'])\n",
    "temp[\"Common_words\"] = list(most_common_bi.keys())\n",
    "temp[\"Count\"] = list(most_common_bi.values())\n",
    "fig = px.bar(temp, x=\"Count\", y=\"Common_words\", title='Commmon Bigrams All Reviews', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_bi_pos = get_top_text_ngrams(df.review[df.sentiment=='positive'],20,2)\n",
    "most_common_bi_pos = dict(most_common_bi_pos)\n",
    "temp = pd.DataFrame(columns = [\"Common_words\" , 'Count'])\n",
    "temp[\"Common_words\"] = list(most_common_bi_pos.keys())\n",
    "temp[\"Count\"] = list(most_common_bi_pos.values())\n",
    "fig = px.bar(temp, x=\"Count\", y=\"Common_words\", title='Commmon Bigrams in Positive Reviews', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_bi_neg = get_top_text_ngrams(df.review[df.sentiment=='negative'],20,2)\n",
    "most_common_bi_neg = dict(most_common_bi_neg)\n",
    "temp = pd.DataFrame(columns = [\"Common_words\" , 'Count'])\n",
    "temp[\"Common_words\"] = list(most_common_bi_neg.keys())\n",
    "temp[\"Count\"] = list(most_common_bi_neg.values())\n",
    "fig = px.bar(temp, x=\"Count\", y=\"Common_words\", title='Commmon Bigrams in Negative Reviews', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_tri = get_top_text_ngrams(df.review,20,3)\n",
    "most_common_tri = dict(most_common_tri)\n",
    "temp = pd.DataFrame(columns = [\"Common_words\" , 'Count'])\n",
    "temp[\"Common_words\"] = list(most_common_tri.keys())\n",
    "temp[\"Count\"] = list(most_common_tri.values())\n",
    "fig = px.bar(temp, x=\"Count\", y=\"Common_words\", title='Common Trigrams All Reviews', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_tri_pos = get_top_text_ngrams(df.review[df.sentiment=='positive'],20,3)\n",
    "most_common_tri_pos = dict(most_common_tri_pos)\n",
    "temp = pd.DataFrame(columns = [\"Common_words\" , 'Count'])\n",
    "temp[\"Common_words\"] = list(most_common_tri_pos.keys())\n",
    "temp[\"Count\"] = list(most_common_tri_pos.values())\n",
    "fig = px.bar(temp, x=\"Count\", y=\"Common_words\", title='Common Trigrams Positive Reviews', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_tri_neg = get_top_text_ngrams(df.review[df.sentiment=='negative'],20,3)\n",
    "most_common_tri_neg = dict(most_common_tri_neg)\n",
    "temp = pd.DataFrame(columns = [\"Common_words\" , 'Count'])\n",
    "temp[\"Common_words\"] = list(most_common_tri_neg.keys())\n",
    "temp[\"Count\"] = list(most_common_tri_neg.values())\n",
    "fig = px.bar(temp, x=\"Count\", y=\"Common_words\", title='Common Trigrams in Negative Reviews', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target column\n",
    "df.sentiment.replace(\"positive\" , 1 , inplace = True)\n",
    "df.sentiment.replace(\"negative\" , 0 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['review']], df.sentiment, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "models = {'lr_count': make_pipeline(count, LogisticRegression(max_iter=1000, random_state=42)),\n",
    "          'dt_count': make_pipeline(count, DecisionTreeClassifier(random_state=42)),\n",
    "          'rf_count': make_pipeline(count, RandomForestClassifier(random_state=42)),\n",
    "          'lr_tfidf': make_pipeline(tfidf, LogisticRegression(max_iter=1000, random_state=42)),\n",
    "          'dt_tfidf': make_pipeline(tfidf, DecisionTreeClassifier(random_state=42)),\n",
    "          'rf_tfidf': make_pipeline(tfidf, RandomForestClassifier(random_state=42))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr_count': 0.8756128986644571,\n",
       " 'dt_count': 0.7171327201737887,\n",
       " 'rf_count': 0.8513636098212689,\n",
       " 'lr_tfidf': 0.8899069735668492,\n",
       " 'dt_tfidf': 0.7103410288997866,\n",
       " 'rf_tfidf': 0.8462421184225345}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "baseline_scores = {}\n",
    "\n",
    "for model in models:\n",
    "    score = cross_val_score(models[model], X_train.iloc[:,0], y_train, scoring='f1')\n",
    "    baseline_scores[model] = score.mean()\n",
    "    \n",
    "baseline_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = models['lr_tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(max_iter=1000, random_state=42))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipeline.fit(X_train.iloc[:,0], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(estimator, X_train, X_test, y_train, y_test, roc_auc='proba'):\n",
    "    '''\n",
    "    Evaluation function to show a few scores for both the train and test set\n",
    "    Also shows a confusion matrix for the test set\n",
    "\n",
    "    roc_auc allows you to set how to calculate the roc_auc score: \n",
    "    'dec' for decision_function or 'proba' for predict_proba \n",
    "    If roc_auc == 'skip', then it ignores calculating the roc_auc_score\n",
    "\n",
    "    Function takes in:\n",
    "    'estimator' a fit sklearn model object\n",
    "    'X_train' dataframe\n",
    "    'X_test' dataframe\n",
    "    'y_train' series\n",
    "    'y_test' series\n",
    "    'roc_auc' string that defines ...\n",
    "    '''\n",
    "    # grab predictions\n",
    "    train_preds = estimator.predict(X_train)\n",
    "    test_preds = estimator.predict(X_test)\n",
    "\n",
    "    # output needed for roc_auc_score\n",
    "    if roc_auc == 'skip':  # skips calculating the roc_auc_score\n",
    "        train_out = False\n",
    "        test_out = False\n",
    "    elif roc_auc == 'dec':  # not all classifiers have decision_function\n",
    "        train_out = estimator.decision_function(X_train)\n",
    "        test_out = estimator.decision_function(X_test)\n",
    "    elif roc_auc == 'proba':\n",
    "        train_out = estimator.predict_proba(\n",
    "            X_train)[:, 1]  # proba for the 1 class\n",
    "        test_out = estimator.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"The value for roc_auc should be 'skip', 'dec' or 'proba'.\")\n",
    "\n",
    "    # print scores\n",
    "    print(\"Train Scores\")\n",
    "    print(\"------------\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_train, train_preds)}\")\n",
    "    print(f\"Precision: {precision_score(y_train, train_preds)}\")\n",
    "    print(f\"Recall: {recall_score(y_train, train_preds)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_train, train_preds)}\")\n",
    "    if type(train_out) == np.ndarray:  # checking for roc_auc\n",
    "        print(f\"ROC-AUC: {roc_auc_score(y_train, train_out)}\")\n",
    "    print(\"----\" * 5)\n",
    "    print(\"Test Scores\")\n",
    "    print(\"-----------\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, test_preds)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, test_preds)}\")\n",
    "    print(f\"Recall: {recall_score(y_test, test_preds)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, test_preds)}\")\n",
    "    if type(test_out) == np.ndarray:\n",
    "        print(f\"ROC-AUC: {roc_auc_score(y_test, test_out)}\")\n",
    "\n",
    "    # plot test confusion matrix\n",
    "    plot_confusion_matrix(estimator, X_test, y_test, values_format=',.5g')\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Scores\n",
      "------------\n",
      "Accuracy: 0.9281066666666666\n",
      "Precision: 0.9213346708199145\n",
      "Recall: 0.9353593825373855\n",
      "F1 Score: 0.9282940581945849\n",
      "ROC-AUC: 0.978660586482951\n",
      "--------------------\n",
      "Test Scores\n",
      "-----------\n",
      "Accuracy: 0.89248\n",
      "Precision: 0.8861424378186312\n",
      "Recall: 0.904303957118083\n",
      "F1 Score: 0.8951310861423221\n",
      "ROC-AUC: 0.9595893116916947\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEGCAYAAAAT05LOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeBElEQVR4nO3de5xVdb3/8dd7hmFELgKOIIEKGqKIqUmkWSZpgalhv7IwCx4d+6EG2e3U0U4nj/bz9/P002M/854aaJlhaeBdD0e8FIp4FxQhL4Agw11ug8zM5/fHXuAWZvbsDbNn9uz1fj4e67HX+q71Xeu7GffH72Wt9VVEYGaWNhXtXQAzs/bg4GdmqeTgZ2ap5OBnZqnk4GdmqdSpvQuQrVfviug/oKSKZC1Y/Er39i6CFWBzbOT9qNPunGPUyK6xanVDXsc++9KWhyJi9O5cr1hKKtL0H9CJP99X097FsAJ8f8iJ7V0EK8BTdffv9jlWrW5g9kP753VsZb8FJfuDLqngZ2alL4BGGtu7GLvNwc/MChIEWyO/Zm8pc/Azs4K55mdmqRMEDWXwWKyDn5kVrBEHPzNLmQAaHPzMLI1c8zOz1Algq/v8zCxtgnCz18xSKKCh48c+Bz8zK0zmCY+Oz8HPzAokGtitdyOUBAc/MytIZsDDwc/MUiZzn5+Dn5mlUKNrfmaWNq75mVkqBaKhDGbAcPAzs4K52WtmqROI96OyvYux2xz8zKwgmZuc3ew1sxTygIeZpU6EaAjX/MwshRpd8zOztMkMeHT80NHxv4GZtSkPeJhZajWUwX1+HT98m1mb2vaERz5LSyS9JellSS9ImpOk9Zb0iKQFyWevrOMvlLRQ0nxJo7LSj07Os1DSVZJajM4OfmZWsMaoyGvJ08iIODIihifbFwAzImIwMCPZRtJQYCxwGDAauFbStrutrwMmAIOTZXRLF3XwM7OCZF5s0Do1v2aMAaYk61OA07PS74iILRHxJrAQGCGpH9AjImZFRAC3ZuVplvv8zKwggdjaeo+3BfCwpABuiIgbgb4RsQwgIpZJ6pMc2x94KivvkiRta7K+Y3pODn5mVpAICrnJuWZbX17ixiTAbXNcRCxNAtwjkl7Lca6m+vEiR3pODn5mViAVcpPzyqy+vJ1ExNLks1bS3cAIYLmkfkmtrx9Qmxy+BNgvK/sAYGmSPqCJ9Jzc52dmBQkyNb98llwkdZXUfds68AXgFWA6MD45bDwwLVmfDoyVVC1pEJmBjdlJE3m9pGOSUd5xWXma5ZqfmRWslV5m2he4O7krpRNwe0Q8KOkZYKqks4FFwBkAETFX0lRgHlAPTIyIhuRc5wGTgS7AA8mSk4OfmRUkUKu8zDQi3gCOaCJ9FXBiM3kuBS5tIn0OMKyQ6zv4mVlBMlNXdvzQ0fG/gZm1MU9abmYpFFDI0xsly8HPzArmmp+ZpU6EXPMzs/TJDHh49jYzSx3P4WFmKZQZ8HCfn5mlUCs94dGuHPzMrCCt9YRHe3PwM7OCeQIjM0udCNja6OBnZimTafY6+JlZCvkJjxS66Lijqe7aQEVlUFEJP733xSaPe/6+vbnlu4fwk3teZP+PbWDJ3K786V8PpG5DJyoqgy9MWsLRp60EYOWiaiZ/bwib1nZiwLCNjLvydTp1bvEt3LaL+g/azIW/Wbh9u99+ddz26wF071nPsZ9fQ2OjWLeqE1f85CBW13Zm5JiVfOV/Ltt+/KBDNvG904bxxqtd26P47c63uuRB0mjg/wGVwE0RcVkxr9dWzr/jFbr1rm92f92GSh6b3I+BR63fnta5SwPfunIBfQbVsW55Z351yhEcevwa9tyrgemXDWTk2Us5+ksrueNnBzHrT335zLfebYuvkkrvvNmFSaceDkBFRXDbrOf5+0O92fBeJbddmXlL+pfGv8s3zn+Hq38+iEen1fDotBoABg7ZxC9ueD21gS+jPJq9RfsGyXya1wAnA0OBM5N5N8vefVfsz0nnvkOn6sbtaX0OrKPPoDoA9ur7Pt1qtrJhdRUR8Prf9+LIL2ZqgZ/8Si0vPdy7XcqdRkd+ah3L3q6mdmk1mzZ8UBfYY8+GJqfA+expq3jsnr3bsISlqTGZx6OlpZQVM3yPABZGxBsR8T5wB5l5Nzu8a755GL865Qj+dnvfnfYtfqUra5Z2ZtiJa5rN/9YL3Wh4X9QcUMfGNZ3o0qOeyuR317PfFta927lYRbcdfPa01R8KZuN/vJhbn3yekV9axW1XDtj5+FNWMTPlwS8z2luZ11LKihn8+gOLs7abnEtT0gRJcyTNWbO6ccfdJedHd73Mv9z/IudNmcfjt/Zj4dM9tu9rbIS7fjmIL//8rWbzr1texW0/PJizLl9ARUXmP6SdlPb/MMtGp6pGPnniGp544INgNuWK/Rj36aN4dPrenDZu+YeOH3LEBurqKnj79T3buqglZdtNzvkspayYwS+vuTQj4saIGB4Rw3v1Lv1+hL36vg9A95qtHDFqFW+/0G37vi0bKlk2f0+uGjuMi447mree784NZx/Kopcyx2xeX8n13x7Kqf/8NoM+vgGAbr3r2fxeJxqSLsS1y6q3X8OKa/hn1/KPuXuydmXVTvtmTqvhuFGrP5TmJu8H3OzNrbk5NjusLZsqqNtQuX39tcd70m/IJh6bvC+PTd6XLj0auOyF2Vz8t2e5+G/PMvCo9Zxz86vs/7EN1L8vbppwCCO+UstRp6zafk4JBh+7jhfuz3SoP/2XPhz++dVNXt9a1wmnrWLmPTXbtz8ysG77+jEnrWHJG3ts35aCz5zs4AcfjPZ29JpfMUd7nwEGJ/NrvgOMBb5RxOsV3fqVVfx2wqEANNaL4WNWMPSEtUz9twM5cPh7OfM+f28NC2f3YOPaTjz95z4AfPPyhQw4bCNjLnyL300awr2X78+AwzZy7NeX5zyX7b7qPRo46tPvcdXPB21P+/ZPFzFgUB0RUPtONb/J2jdsxHpWvtuZdxfv0dTpUqccRnsVTXY6tdLJpS8CvyZzq8stybRzzRr2sc7x5/tqch1Skq7/9qF854bXUnlv3veHNDnDoJWop+ruZ13jqt2qkvU6pE987pav5nXsXcdd92xEDN+d6xVLUe/zi4j7gfuLeY1ScO7vXm3vIpi1qVJv0ubDT3iYWUH8hIeZpZaDn5mljl9mamapVer38OXDwc/MChIB9X6ZqZmlkZu9ZpY67vMzs9QKBz8zSyMPeJhZ6kSUR59fxx+yMbM2JhoaK/Ja8jqbVCnpeUn3Jtu9JT0iaUHy2Svr2AslLZQ0X9KorPSjJb2c7LtKUovR2cHPzAoWobyWPH0fyH5A/gJgRkQMBmYk2yTTYIwFDgNGA9cm02UAXAdMAAYny+iWLurgZ2YFac33+UkaAJwC3JSVPAaYkqxPAU7PSr8jIrZExJvAQmCEpH5Aj4iYFZnXVN2aladZ7vMzs8JEM9MvNK1G0pys7Rsj4sas7V8DPwW6Z6X1jYhlABGxTFKfJL0/8FTWcdumxtiarO+YnpODn5kVrIDR3pXNvc9P0qlAbUQ8K+mEPM7V3NQYeU2ZsSMHPzMrSCQDHq3gOOBLyUuP9wB6SPo9sFxSv6TW1w+oTY5vbmqMJcn6juk5uc/PzAoWkd+S+xxxYUQMiIiBZAYy/jsivglMB8Ynh40HpiXr04GxkqqT6TEGA7OTJvJ6Sccko7zjsvI0yzU/MytYkZ/wuAyYKulsYBFwRuaaMVfSVGAeUA9MjIiGJM95wGSgC/BAsuTk4GdmBcnU6lo3+EXETGBmsr4KaHJymGQeoJ3mAoqIOcCwQq7p4GdmBSuHJzwc/MysYEWc9LHNOPiZWUEC0eiXmZpZGpVBxc/Bz8wKVIQBj/bg4GdmhSuDqp+Dn5kVrKxrfpJ+Q474HhHnF6VEZlbSAmhsLOPgB8zJsc/M0iqAcq75RcSU7G1JXSNiY/GLZGalrhzu82vxZh1Jx0qaR/KmVUlHSLq26CUzs9IVeS4lLJ87FX8NjAJWAUTEi8DxRSyTmZW0/F5hX+qDInmN9kbE4h3mA2lo7lgzS4ESr9XlI5/gt1jSp4CQ1Bk4nw9PNmJmaRIQZTDam0+z91xgIpl34r8DHJlsm1lqKc+ldLVY84uIlcBZbVAWM+soyqDZm89o74GS7pG0QlKtpGmSDmyLwplZiUrJaO/twFSgH/AR4E7gj8UslJmVsG03OeezlLB8gp8i4raIqE+W31PyMd3Miqk1JjBqb7me7e2drD4q6QLgDjJB7+vAfW1QNjMrVWUw2ptrwONZPjwh8DlZ+wL4ZbEKZWalTSVeq8tHrmd7B7VlQcysg+gAgxn5yOsJD0nDgKFkZlUHICJuLVahzKyUlf5gRj5aDH6SLgJOIBP87gdOBp4EHPzM0qoMan75jPZ+lcwEwu9GxLeBI4DqopbKzEpbY55LCcun2bs5Ihol1UvqAdQCvsnZLK3K/WWmWeZI6gn8lswI8AZgdjELZWalraxHe7eJiO8mq9dLehDoEREvFbdYZlbSyjn4Sfp4rn0R8VxximRmVny5an5X5NgXwOdauSwserkb3zvguNY+rRXRQ0ufau8iWAFGjGqdaXjKutkbESPbsiBm1kEEZf94m5lZ08q55mdm1pxyaPbmc5OzmdmHtcLLTCXtIWm2pBclzZV0cZLeW9IjkhYkn72y8lwoaaGk+ZJGZaUfLenlZN9V2mHGtabk8yZnSfqmpF8k2/tLGtFSPjMrY63zJuctwOci4ggycwONlnQMcAEwIyIGAzOSbSQNBcYChwGjgWslVSbnug6YAAxOltEtXTyfmt+1wLHAmcn2euCaPPKZWRlS5L/kEhkbks2qZAlgDDAlSZ8CnJ6sjwHuiIgtEfEmsBAYIakfmfuPZ0VEkHnvwLY8zcon+H0yIiYCdUmB1wCd88hnZuWqUfktUCNpTtYyIfs0kiolvUDmsdlHIuJpoG9ELANIPvskh/cHFmdlX5Kk9U/Wd0zPKZ8Bj61J1TKSwu5DyT+ybGbFVMCAx8qIGN7czohoAI5MHqG9O3l9XrOXbeoUOdJzyqfmdxVwN9BH0qVkXmf1v/PIZ2blqpVnb4uItcBMMn11y5OmLMlnbXLYEmC/rGwDgKVJ+oAm0nNqMfhFxB+AnwL/B1gGnB4Rd7aUz8zKVCv1+UnaJ6nxIakLcBLwGjAdGJ8cNh6YlqxPB8ZKqpY0iMzAxuykabxe0jHJKO+4rDzNyudlpvsDm4B7stMiYlFLec2sTLXOfX79gClJt1oFMDUi7pU0C5gq6WxgEXAGQETMlTQVmAfUAxOTZjPAecBkoAvwQLLklE+f33180K7eAxgEzCcz3GxmKaRW6PVP3g51VBPpq8i8QLmpPJcClzaRPgfI1V+4k3xeaXV49nbytpdzmjnczKxDKPjxtoh4TtInilEYM+sgyuDxtnz6/H6UtVkBfBxYUbQSmVlpy2MwoyPIp+bXPWu9nkwf4F+KUxwz6xDKPfglozDdIuInbVQeM+sIyjn4SeoUEfW5XmdvZukjWme0t73lqvnNJtO/94Kk6cCdwPZ3YEfEXUUum5mVohT1+fUGVpGZs2Pb/X4BOPiZpVWZB78+yUjvK+z88HAZfHUz22VlEAFyBb9KoBu7+MYEMytf5d7sXRYRl7RZScys4yjz4Nfx56Yzs9YX5T/a2+SDxWZmZV3zi4jVbVkQM+s4yr3Pz8ysaQ5+ZpY6Bb6ivlQ5+JlZQYSbvWaWUg5+ZpZODn5mlkoOfmaWOil6q4uZ2Yc5+JlZGpX7421mZk1ys9fM0sc3OZtZajn4mVna+AkPM0stNXb86OfgZ2aFcZ+fmaWVm71mlk4OfmaWRq75mVk6OfiZWeqUyextFe1dADPrWLbd55fPkvM80n6SHpX0qqS5kr6fpPeW9IikBclnr6w8F0paKGm+pFFZ6UdLejnZd5WkFqfedfAzs8JF5LfkVg/8OCIOBY4BJkoaClwAzIiIwcCMZJtk31jgMGA0cK2kyuRc1wETgMHJMrqlizv4mVnBWqPmFxHLIuK5ZH098CrQHxgDTEkOmwKcnqyPAe6IiC0R8SawEBghqR/QIyJmRUQAt2blaZb7/FpB1x4N/PDyxQw8pI4I+M8f7ceSf1Tzs+vfpu+A91m+pDOXnnMAG9Z1YuSX13DGd2u35x10aB0TRx3MG3O7tOM3KG/jRgylS7cGKiqgslNw9YOvf2j/9Rd9hBf/1h2ALXVi7coq7nrtZZYvqeKSswfR2CDq62HMP63k1HGrgEylZvJ/7MsT9/akogJOHbeS07+zss2/W7so7CbnGklzsrZvjIgbdzxI0kDgKOBpoG9ELINMgJTUJzmsP/BUVrYlSdrWZH3H9JyKFvwk3QKcCtRGxLBiXacUnHfJO8yZ2Z3/NWEgnaoaqe4SjD1/Oc8/2Y2pV/fla5OW8/VJtdx86Ud49O5ePHp3pgtj4CGb+fffveXA1wZ+dedC9tq7ocl95168dPv6tJtrWPhK5u/Ru089V05fQOfqYPPGCs4ZeQjHfmEde+9bz8N/6s2KpZ256fHXqKiAtSvTVY8oYMBjZUQMz3kuqRvwF+AHEfFeju66pnZEjvScitnsnUwe7e6Obs9uDRx+zEYevL03APVbK9j4XiXHjnqP/5qaSfuvqb05dvR7O+UdefpaZv61Z1sW11rw6F97ccLpawCo6hx0rs78hrZuEY1ZP/h7b92bs374LhXJL6hnTX1bF7VdqTG/pcXzSFVkAt8fIuKuJHl50pQl+dzWVFoC7JeVfQCwNEkf0ER6TkULfhHxOLC6WOcvFfse8D7rVlXy4ysXc83D8/nB5Yup7tJAr5qtrK6tAmB1bRU99975x3H8l9byqINf8Sn42ZkHMXHUwdz/+72bPWz5kiqWL+7MkZ/esD2t9p0qzj1xCN8cfhhfm1jL3vtm/o7L3q7msem9mDT6YP71rAN5543ORf8aJSNolQGPZET2ZuDViPjPrF3TgfHJ+nhgWlb6WEnVkgaRGdiYnTSR10s6JjnnuKw8zWr3AQ9JEyTNkTRnK1vauzgFq6wMPnr4Zu69dW8mfmEIdZsq+Pqk2hbzDTlqI1s2V/D2fDd5i+3KaQu45uHXufQPbzB9cg0vP9W1yeNm/rUXnz5lLZWVH6T16b+V62fM53d/n8cjd/ZizYpM83brFtG5upGrH3ydk89axRU/2r8tvkrJaI0BD+A44FvA5yS9kCxfBC4DPi9pAfD5ZJuImAtMBeYBDwITI2JbX8Z5wE1kBkH+ATzQ0sXbPfhFxI0RMTwihldR3d7FKdjKZVWsWFbF/OczP6gn792Ljx6+mTUrq+jdZysAvftsZe2qD/cJnTDGTd62sq221rOmnuNGr+O15/ds8rjHpvXc3uRt6hwHHFzHK09n/s41/bby6VPWAXDcyet489WU/U8s8lxynSLiyYhQRHwsIo5MlvsjYlVEnBgRg5PP1Vl5Lo2IgyJiSEQ8kJU+JyKGJfsmJaO+ObV78Ovo1qyoYuXSzgw4qA6AIz+zgUUL9uCph3tw0tcyf7OTvraaWQ/12J5HCj5z6jpmTuvZHkVOlbpNFWzaULF9/dnHujPwkDqm3VLDtFtqth+3eGE1G9Z1YujwTdvTViytYsvmTF/6+rWVzJvTlQEHZVonnxq9jhef7AbAS7O6MeDAjtdq2VWtdZNze0vXEFWRXPPz/vzL1YvoVBW8u6gzV/xwP1QB/3r924weu5radzK3umxz+DEbWbmsincXdbyabkezZkUnLj57EAAN9TDyy2v5xMj1XP1IDw77xMbtx838ay8+O2YN2QONixZU89tLDsz82gO+eu4KBh2a+Z/c1yfV8h+T9ueu3+5Dl66N/ODyRW35tdpXRFm8zFR51A537cTSH4ETgBpgOXBRRNycK08P9Y5P6sSilMeK46GlL7R3EXbJv40bxC9ueouqzh3/R1yIEaMWM+fFuhYf/cqle88BcdTx38/r2Cfu+emzLd3q0l6KVvOLiDOLdW6z3fXLW99s7yJ0aKXepM2Hm71mVpgAyqDZ6+BnZoXr+LHPwc/MCudmr5mlUjmM9jr4mVlhPHWlmaVR5ibnjh/9HPzMrHBlMIeHg5+ZFcw1PzNLH/f5mVk6lcezvQ5+ZlY4N3vNLHXKZNJyBz8zK5xrfmaWSh0/9jn4mVnh1Njx270OfmZWmMA3OZtZ+ojwTc5mllIOfmaWSg5+ZpY67vMzs7TyaK+ZpVC42WtmKRQ4+JlZSnX8Vq+Dn5kVzvf5mVk6OfiZWepEQEPHb/c6+JlZ4VzzM7NUKoPgV9HeBTCzDiaAxshvaYGkWyTVSnolK623pEckLUg+e2Xtu1DSQknzJY3KSj9a0svJvqskqaVrO/iZWYECojG/pWWTgdE7pF0AzIiIwcCMZBtJQ4GxwGFJnmslVSZ5rgMmAIOTZcdz7sTBz8wKE2QGPPJZWjpVxOPA6h2SxwBTkvUpwOlZ6XdExJaIeBNYCIyQ1A/oERGzIiKAW7PyNMt9fmZWuPz7/GokzcnavjEibmwhT9+IWJa5TCyT1CdJ7w88lXXckiRta7K+Y3pODn5mVrj8g9/KiBjeSldtqh8vcqTn5GavmRUoebFBPsuuWZ40ZUk+a5P0JcB+WccNAJYm6QOaSM/Jwc/MChNAY2N+y66ZDoxP1scD07LSx0qqljSIzMDG7KSJvF7SMcko77isPM1ys9fMCtdK9/lJ+iNwApm+wSXARcBlwFRJZwOLgDMyl4y5kqYC84B6YGJENCSnOo/MyHEX4IFkycnBz8wK1HqPt0XEmc3sOrGZ4y8FLm0ifQ4wrJBrO/iZWWECIr97+Eqag5+ZFS6PpzdKnYOfmRWuDJ7tdfAzs8JE7M5Ibslw8DOzwrnmZ2bpE0RDQ8uHlTgHPzMrzLZXWnVwDn5mVjjf6mJmaRNAuOZnZqkT4ZqfmaVTOQx4KEpoyFrSCuDt9i5HEdQAK9u7EFaQcv2bHRAR++zOCSQ9SObfJx8rI6LFV8q3h5IKfuVK0pxWfKGjtQH/zcqf3+dnZqnk4GdmqeTg1zZamrDFSo//ZmXOfX5mlkqu+ZlZKjn4mVkqOfgVkaTRkuZLWijpgvYuj7VM0i2SaiW90t5lseJy8CsSSZXANcDJwFDgTElD27dUlofJQEnelGuty8GveEYACyPijYh4H7gDGNPOZbIWRMTjwOr2LocVn4Nf8fQHFmdtL0nSzKwEOPgVj5pI831FZiXCwa94lgD7ZW0PAJa2U1nMbAcOfsXzDDBY0iBJnYGxwPR2LpOZJRz8iiQi6oFJwEPAq8DUiJjbvqWylkj6IzALGCJpiaSz27tMVhx+vM3MUsk1PzNLJQc/M0slBz8zSyUHPzNLJQc/M0slB78ORFKDpBckvSLpTkl77sa5Jkv6arJ+U66XLkg6QdKnduEab0naaZav5tJ3OGZDgdf6d0n/XGgZLb0c/DqWzRFxZEQMA94Hzs3embxJpmAR8Z2ImJfjkBOAgoOfWSlz8Ou4ngA+mtTKHpV0O/CypEpJ/1fSM5JeknQOgDKuljRP0n1An20nkjRT0vBkfbSk5yS9KGmGpIFkguwPk1rnZyTtI+kvyTWekXRckndvSQ9Lel7SDTT9fPOHSPqrpGclzZU0YYd9VyRlmSFpnyTtIEkPJnmekHRIq/xrWup0au8CWOEkdSLznsAHk6QRwLCIeDMJIOsi4hOSqoG/SXoYOAoYAhwO9AXmAbfscN59gN8Cxyfn6h0RqyVdD2yIiMuT424HroyIJyXtT+YplkOBi4AnI+ISSacAHwpmzfin5BpdgGck/SUiVgFdgeci4seSfpGcexKZiYXOjYgFkj4JXAt8bhf+GS3lHPw6li6SXkjWnwBuJtMcnR0RbybpXwA+tq0/D9gLGAwcD/wxIhqApZL+u4nzHwM8vu1cEdHce+1OAoZK2yt2PSR1T67xP5K890lak8d3Ol/Sl5P1/ZKyrgIagT8l6b8H7pLULfm+d2ZduzqPa5jtxMGvY9kcEUdmJyRBYGN2EvC9iHhoh+O+SMuv1FIex0Cmu+TYiNjcRFnyfl5S0glkAumxEbFJ0kxgj2YOj+S6a3f8NzDbFe7zKz8PAedJqgKQdLCkrsDjwNikT7AfMLKJvLOAz0oalOTtnaSvB7pnHfcwmSYoyXFHJquPA2claScDvVoo617AmiTwHUKm5rlNBbCt9voNMs3p94A3JZ2RXEOSjmjhGmZNcvArPzeR6c97LpmE5wYyNfy7gQXAy8B1wGM7ZoyIFWT66e6S9CIfNDvvAb68bcADOB8YngyozOODUeeLgeMlPUem+b2ohbI+CHSS9BLwS+CprH0bgcMkPUumT++SJP0s4OykfHPx1AC2i/xWFzNLJdf8zCyVHPzMLJUc/MwslRz8zCyVHPzMLJUc/MwslRz8zCyV/j80L9rQD2ieQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate(lr_pipeline, X_train.iloc[:,0], X_test.iloc[:,0], y_train, y_test, roc_auc='proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipeline.steps[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fit tfidf vectorizer\n",
    "transformer = lr_pipeline.steps[0][-1]\n",
    "# the fit logistic regression model\n",
    "lr_model = lr_pipeline.steps[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_inspect = transformer.transform(X_test.iloc[:,0]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = permutation_importance(lr_model, X_inspect, y_test, random_state=42, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the names of the features \n",
    "# with the features permutation importance\n",
    "importance_weights = list(zip(transformer.get_feature_names(), importance['importances_mean']))\n",
    "\n",
    "# Sort the weights in descending order\n",
    "sorted(importance_weights, key=lambda x: x[1], reverse=True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
